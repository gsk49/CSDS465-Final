{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import np vectors used in classification\n",
    "avis = []\n",
    "lab = []\n",
    "\n",
    "labels = [[\"sinker\",0], [\"curve\", 1]]\n",
    "labels2 = [[\"ball\", 1], [\"strike\", 0]]\n",
    "\n",
    "split = int(len(avis)*3/4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = map(\n",
    "    torch.tensor, (avis[:split], avis[split:], lab[:split], lab[split:]))\n",
    "\n",
    "y_names = labels[:][0]\n",
    "labels = labels[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "\n",
    "        self.conv5 = nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=2)\n",
    "        self.bn5 = nn.BatchNorm2d(16)\n",
    "        self.conv6 = nn.Conv2d(16, 4, kernel_size=3, stride=2, padding=2)\n",
    "        self.bn6 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.fc1 = nn.Linear(3772, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.dropout(x, 0.3, training=self.training)\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.dropout(x, 0.3, training=self.training)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.3, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_frames(video_path, frame_indices):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if the video file is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open video file.\")\n",
    "        return\n",
    "\n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    rev_idxs = (total_frames-1)*np.ones(len(frame_indices))-np.array(frame_indices)\n",
    "    # Extract frames at specified indices\n",
    "    for idx in rev_idxs:\n",
    "        # Set the frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "\n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame is read successfully\n",
    "        if ret:\n",
    "            # Save the frame\n",
    "            # cv2.imwrite(f\"{output_folder}/frame_{idx}.jpg\", frame)\n",
    "            # print(f\"Frame {idx} saved successfully.\")\n",
    "            break\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: Unable to read frame {idx}.\")\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    return frame\n",
    "\n",
    "# Example usage\n",
    "video_path = \"test.avi\"\n",
    "output_folder = \"output_frames\"\n",
    "frame_indices = [0, 1, 2]  # Specify the indices of frames you want to extract\n",
    "\n",
    "# Call the function to extract frames\n",
    "frames = extract_frames(video_path, frame_indices)\n",
    "print(frames[0].shape)\n",
    "# print(frames[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, x_test, y_train, y_test):\n",
    "\n",
    "    x_test = x_test.view(-1, 3, 720, 1280)\n",
    "    x_train = x_train.view(-1, 3, 720, 1280)\n",
    "\n",
    "    y_train = y_train.long()\n",
    "    y_test = y_test.long()\n",
    "\n",
    "    model = Network()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=.2)\n",
    "\n",
    "    # create the train dataset and loader (following pytorch documentation)\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "    epochs = 12\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.view(-1, 3, 720, 1280)\n",
    "            labels = labels.view(-1)\n",
    "            # print(\"labels: \", labels)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs.float())\n",
    "            #print(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"epoch: \",str(epoch))\n",
    "\n",
    "    test_outputs = model(x_test.float())\n",
    "    _, test_predicted = torch.max(test_outputs, 1)\n",
    "    test_accuracy = (test_predicted == y_test).sum().item() / len(y_test)\n",
    "\n",
    "    train_outputs = model(x_train.float())\n",
    "    _, train_predicted = torch.max(train_outputs, 1)\n",
    "    train_accuracy = (train_predicted ==\n",
    "                        y_train).sum().item() / len(y_train)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}, Test Accuracy: {test_accuracy * 100:.2f}%, Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "\n",
    "    torch.save(model.state_dict(), \"model/model1.pth\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "### The [0] gets the last frame, [5] would get 5th to last, etc.\n",
    "path = \"./avis_strike\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "strikes = []\n",
    "for file in files:\n",
    "    strikes.append(extract_frames(path+\"/\"+file, [0]))\n",
    "\n",
    "path = \"./avis_ball\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "balls = []\n",
    "for file in files:\n",
    "    balls.append(extract_frames(path+\"/\"+file, [0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/7_x2mx414t7fk4_n041gwvyc0000gn/T/ipykernel_49605/3893506297.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403226260/work/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  x_train = torch.tensor(x_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 720, 1280, 3])\n",
      "torch.Size([37, 720, 1280, 3])\n",
      "torch.Size([13])\n",
      "torch.Size([37])\n"
     ]
    }
   ],
   "source": [
    "b_idx = int(len(balls)*.75)\n",
    "s_idx = int(len(strikes)*.75)\n",
    "\n",
    "print(b_idx)\n",
    "print(s_idx)\n",
    "\n",
    "x_train = balls[:b_idx] + strikes[:s_idx]\n",
    "x_train = torch.tensor(x_train)\n",
    "x_train = torch.squeeze(x_train)\n",
    "\n",
    "x_test = balls[b_idx:] + strikes[s_idx:]\n",
    "x_test = torch.tensor(x_test)\n",
    "x_test = torch.squeeze(x_test)\n",
    "\n",
    "y_train = torch.tensor(np.concatenate((np.zeros( b_idx), np.ones(s_idx))))\n",
    "y_test = torch.tensor(np.concatenate((np.zeros(len(balls)-b_idx), np.ones(len(strikes)-s_idx))))\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x3772 and 96x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(x_train, x_test, y_train, y_test)\n",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m# print(\"labels: \", labels)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m     26\u001b[0m \u001b[39m#print(outputs)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 31\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, \u001b[39m0.3\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m     30\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Flatten layer\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     32\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, \u001b[39m0.3\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[1;32m     33\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x3772 and 96x128)"
     ]
    }
   ],
   "source": [
    "train(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start of Pitch-Type Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3263.1624651334137.avi', '607.7366191253092.avi', '5888.617335929688.avi', '3517.911483333333.avi', '855.7366191253092.avi', '11428.69556865428.avi', '2132.546333333333.avi', '4436.87213830851.avi', '1356.7394060727393.avi', '10042.162465133413.avi', '4170.6955686542815.avi', '8043.317851692016.avi', '3933.6677.avi', '1634.7366191253095.avi', '11995.73940607274.avi', '2104.546333333333.avi', '11413.69556865428.avi', '3342.67330666807.avi', '4274.546333333334.avi', '7907.009788958476.avi', '8439.587890111046.avi', '571.67330666807.avi', '12610.317851692016.avi', '5882.7366191253095.avi', '12811.739406072738.avi', '9948.162465133413.avi', '7833.009788958476.avi', '3952.6676999999995.avi', '7746.73661912531.avi', '5645.831219409505.avi', '12185.317851692018.avi', '4427.158933333333.avi', '1675.6733066680704.avi', '4529.546333333333.avi', '8743.321983333333.avi', '2594.6676999999995.avi', '4191.009788958476.avi', '5388.546333333334.avi', '5429.546333333334.avi', '602.8312194095048.avi', '4578.695568654282.avi', '3544.162465133414.avi', '6649.317851692017.avi', '11502.69556865428.avi', '8188.158933333333.avi', '11015.158933333332.avi', '9197.546333333335.avi', '6843.009788958476.avi', '7045.408267985896.avi', '3128.695568654281.avi', '1412.6677.avi', '8481.587890111048.avi', '5849.317851692017.avi', '4844.11805.avi', '6093.317851692016.avi', '1096.1624651334141.avi', '10553.73940607274.avi', '7656.317851692017.avi', '4479.162465133413.avi', '6878.11805.avi', '774.8312194095047.avi', '1845.6733066680702.avi', '18702.158933333332.avi', '8922.587890111046.avi', '12508.317851692018.avi', '1740.8721383085103.avi', '9570.911483333333.avi', '12476.317851692018.avi', '2516.8312194095047.avi', '8446.11805.avi', '4418.546333333334.avi', '888.67330666807.avi', '5655.587890111047.avi', '1458.1624651334141.avi', '4171.67330666807.avi', '9136.69556865428.avi', '1341.162465133414.avi', '13296.321983333335.avi', '6239.009788958476.avi', '4308.736619125309.avi', '5288.667699999999.avi', '11322.158933333332.avi', '5874.317851692016.avi', '640.67330666807.avi', '1787.8721383085103.avi', '9323.739406072738.avi', '1912.5463333333332.avi', '5323.6677.avi', '9161.158933333332.avi', '12843.73940607274.avi', '10342.6677.avi', '4372.7366191253095.avi', '4310.546333333334.avi', '1611.6733066680702.avi', '10549.158933333332.avi', '6367.009788958476.avi', '2955.162465133414.avi', '6662.831219409505.avi', '9615.162465133413.avi', '2379.158933333333.avi', '7514.317851692016.avi', '1552.11805.avi', '5141.667699999999.avi', '4255.872138308509.avi', '11971.739406072738.avi', '1850.9114833333333.avi', '10521.158933333332.avi', '10375.739406072738.avi', '6149.162465133414.avi', '720.1848060628388.avi', '3436.546333333333.avi', '1217.1624651334141.avi', '3364.67330666807.avi', '13739.73940607274.avi', '11604.69556865428.avi', '5802.695568654282.avi', '1634.11805.avi', '5478.546333333334.avi', '4209.162465133414.avi', '2134.6733066680704.avi', '8387.009788958476.avi', '3049.6733066680695.avi', '4922.739406072739.avi', '8612.587890111048.avi', '3364.546333333333.avi', '7573.317851692016.avi', '5264.667699999999.avi', '8715.321983333333.avi', '5585.911483333333.avi', '594.6733066680702.avi', '4537.872138308511.avi', '11351.695568654282.avi', '1005.5463333333335.avi', '10416.911483333333.avi', '12204.317851692016.avi', '6199.7366191253095.avi', '5129.118049999999.avi', '3480.1589333333336.avi', '2926.546333333333.avi', '5187.695568654282.avi', '1592.6733066680702.avi', '6274.009788958476.avi', '2120.184806062839.avi', '9167.118050000001.avi', '8929.317851692016.avi', '2904.695568654281.avi', '5149.11805.avi', '8886.158933333334.avi', '2469.1589333333336.avi', '1902.11805.avi', '4608.911483333332.avi', '2168.8721383085103.avi', '2892.67330666807.avi', '6184.695568654282.avi', '5678.7366191253095.avi', '4577.162465133414.avi', '7852.009788958476.avi', '4251.67330666807.avi', '5556.831219409504.avi', '3320.67330666807.avi', '580.1848060628388.avi', '10944.158933333334.avi', '9029.69556865428.avi', '5407.831219409505.avi', '8605.11805.avi', '7922.317851692017.avi', '6074.695568654282.avi', '1441.1624651334141.avi', '2395.1624651334146.avi', '4336.162465133414.avi', '9288.162465133413.avi', '1044.87213830851.avi', '9436.911483333335.avi', '7321.739406072739.avi', '13548.321983333333.avi', '1178.5463333333335.avi', '549.1848060628389.avi', '9330.162465133413.avi', '8799.587890111046.avi', '1658.11805.avi', '3272.1589333333336.avi', '1189.0097889584758.avi', '8028.158933333333.avi', '2885.695568654281.avi', '1132.5463333333332.avi', '8965.317851692016.avi', '4223.162465133414.avi', '8848.317851692016.avi', '4343.546333333334.avi', '4259.162465133414.avi', '1575.7366191253093.avi', '4113.6677.avi', '1657.6733066680702.avi', '5853.7366191253095.avi', '10483.69556865428.avi', '9410.158933333332.avi', '4209.158933333333.avi', '5015.667699999999.avi', '13483.317851692016.avi', '6942.911483333333.avi', '961.0097889584758.avi', '4555.6955686542815.avi', '3691.831219409505.avi', '2962.11805.avi', '10586.158933333332.avi', '843.6733066680702.avi', '6514.317851692017.avi', '5825.617335929688.avi', '6284.73661912531.avi', '3116.67330666807.avi', '11612.158933333334.avi', '6059.617335929688.avi', '2038.6733066680702.avi', '2110.009788958476.avi', '8810.317851692016.avi', '6979.667699999999.avi', '1113.7394060727393.avi', '7558.158933333334.avi', '5599.546333333333.avi', '863.67330666807.avi', '6045.7366191253095.avi', '3078.009788958476.avi', '6173.73661912531.avi', '3572.8312194095047.avi', '4167.6677.avi', '5660.546333333333.avi', '1072.1624651334141.avi', '8822.321983333335.avi', '8096.158933333333.avi', '3850.6677.avi', '10889.158933333332.avi', '1829.11805.avi', '3139.736619125309.avi', '11634.69556865428.avi', '3062.736619125309.avi', '11436.158933333332.avi', '5750.7366191253095.avi', '5977.7366191253095.avi', '5150.162465133413.avi', '7505.739406072739.avi', '8083.911483333333.avi', '1661.7366191253093.avi', '5463.6955686542815.avi', '946.1848060628387.avi', '10650.6677.avi', '2068.546333333333.avi', '5633.546333333334.avi', '8452.009788958476.avi', '8380.587890111048.avi', '7930.009788958476.avi', '6722.158933333333.avi', '2874.7366191253086.avi', '9020.118050000001.avi', '9360.162465133413.avi', '4272.009788958476.avi', '13234.321983333335.avi', '6457.695568654282.avi', '3084.7366191253086.avi', '664.6733066680702.avi', '7730.317851692017.avi', '11107.69556865428.avi', '8449.321983333333.avi', '4392.546333333333.avi', '6574.317851692016.avi', '4288.546333333333.avi', '2221.184806062839.avi', '4615.162465133414.avi', '2322.162465133414.avi', '2224.87213830851.avi', '5072.009788958476.avi', '6388.162465133414.avi', '6059.317851692016.avi', '4860.739406072739.avi', '7822.6955686542815.avi', '2771.736619125309.avi', '2242.162465133414.avi', '8099.911483333332.avi', '2853.736619125309.avi', '3870.6677.avi', '2067.009788958476.avi', '4595.162465133413.avi', '801.1848060628388.avi', '9267.162465133413.avi', '8021.317851692017.avi', '9214.158933333334.avi', '13404.321983333333.avi', '10447.6677.avi', '7067.911483333332.avi', '11428.009788958476.avi', '7873.695568654282.avi', '4385.009788958476.avi', '3084.67330666807.avi', '2815.736619125309.avi', '3238.67330666807.avi', '6190.317851692017.avi', '6915.617335929688.avi', '2309.162465133414.avi', '992.0097889584758.avi', '1725.6733066680702.avi', '3146.009788958476.avi', '4459.162465133414.avi', '2691.1624651334146.avi', '4236.7366191253095.avi', '2164.6733066680704.avi', '2918.162465133414.avi', '2863.695568654281.avi', '8640.587890111046.avi', '3613.7394060727397.avi', '5627.831219409504.avi', '9081.69556865428.avi', '8682.321983333331.avi', '5173.118049999999.avi', '10554.6677.avi', '6610.317851692017.avi', '615.67330666807.avi', '1749.6733066680702.avi', '10356.667700000002.avi', '2338.162465133414.avi', '5339.6955686542815.avi', '10103.162465133415.avi', '1087.1848060628388.avi', '1290.6955686542815.avi', '6308.317851692017.avi', '1054.1848060628388.avi', '5159.6955686542815.avi', '3105.009788958476.avi', '11151.009788958476.avi', '12248.317851692018.avi', '2753.6676999999995.avi', '2089.009788958476.avi', '5968.695568654282.avi', '5025.009788958475.avi', '5688.546333333333.avi', '3964.184806062839.avi', '2457.695568654281.avi', '3722.8312194095047.avi', '7999.911483333332.avi', '15374.158933333334.avi', '5204.6955686542815.avi', '5318.6955686542815.avi', '6141.617335929688.avi', '7690.6955686542815.avi', '9784.69556865428.avi', '6368.162465133414.avi', '11953.73940607274.avi', '2105.6733066680704.avi', '7781.317851692016.avi', '9358.739406072738.avi', '4089.6677.avi', '2451.8312194095047.avi', '4495.546333333334.avi', '2312.1589333333336.avi', '5001.009788958476.avi', '4358.162465133414.avi', '2448.184806062839.avi', '13369.321983333335.avi', '696.8721383085101.avi', '18786.158933333332.avi', '4758.587890111047.avi', '1186.1848060628388.avi', '5620.667699999999.avi', '6749.317851692017.avi', '2475.695568654281.avi', '2581.4082679858952.avi']\n",
      "4259.162465133414.avi\n",
      "2918.162465133414.avi\n",
      "9267.162465133413.avi\n",
      "3722.8312194095047.avi\n",
      "11953.73940607274.avi\n",
      "10553.73940607274.avi\n",
      "4459.162465133414.avi\n",
      "3691.831219409505.avi\n",
      "1441.1624651334141.avi\n",
      "1458.1624651334141.avi\n",
      "2322.162465133414.avi\n",
      "4758.587890111047.avi\n",
      "2955.162465133414.avi\n",
      "4577.162465133414.avi\n",
      "4860.739406072739.avi\n",
      "1850.9114833333333.avi\n",
      "10042.162465133413.avi\n",
      "7321.739406072739.avi\n",
      "602.8312194095048.avi\n",
      "8640.587890111046.avi\n",
      "11995.73940607274.avi\n",
      "2451.8312194095047.avi\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filenames = []\n",
    "with open('./pitch_types/curves.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "\n",
    "    for row in reader:\n",
    "        filenames.append(row['Title'])\n",
    "\n",
    "print(filenames)\n",
    "\n",
    "path = \"./0strike_avis\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "curves = []\n",
    "for file in files:\n",
    "    if file in filenames:\n",
    "        curves.append(extract_frames(path+\"/\"+file, [0]))\n",
    "\n",
    "# All pitch types can be implemented the same as above, \n",
    "# path should include both 0strike_avis and 0ball_avis\n",
    "sliders = []\n",
    "fasts = []\n",
    "\n",
    "\n",
    "curve_idx = int(len(curves)*.75)\n",
    "slider_idx = int(len(sliders)*.75)\n",
    "fast_idx = int(len(fasts)*.75)\n",
    "\n",
    "x_train = curves[:curve_idx] + sliders[:slider_idx]+fasts[:fast_idx]\n",
    "x_train = torch.tensor(x_train)\n",
    "x_train = torch.squeeze(x_train)\n",
    "\n",
    "x_test = curves[curve_idx:] + sliders[slider_idx:]+fasts[fast_idx:]\n",
    "x_test = torch.tensor(x_test)\n",
    "x_test = torch.squeeze(x_test)\n",
    "\n",
    "y_train = torch.tensor(np.concatenate((np.zeros( curve_idx), np.ones(slider_idx), 2*np.ones(fast_idx))))\n",
    "y_test = torch.tensor(np.concatenate((np.zeros(len(curves)-curve_idx), np.ones(len(sliders)-slider_idx), 2*np.ones(len(fasts)-fast_idx))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
